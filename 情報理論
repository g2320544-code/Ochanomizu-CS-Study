ハフマン符号の構成と平均符号長　　全体なぜなぜそうなるか何に使うか何に使われるから出されているか
ある文字列 (情報) をハフマン符号化する場合、次の1-3を順にすればOK。
各文字(情報)を出現確率（出現頻度）の高い順に並べ、それぞれを独立したグループと考える
各グループの中で、出現確率が低い2つのグループを1つにしていきながら、グループが1つになるまで二分木を作っていく。
作成した二分木から、各文字ごとの符号を求める
各文字ごとに「符号長（符号の文字数） × 出現確率」を求め、それらを足すことで求めることができます
二分木の各節(ノード)の左側を0、右側を1とする
各文字（A～F）ごとに、以下の操作を実施
木構造の一番上の部分から対応するノードまでたどっていく
たどった際に通った0, 1を左から順番に並べたものを符号にする

エントロピー
ハフマン符号の構成と平均符号長を求める手順を解説します。
💡 ハフマン符号の構成手順
与えられた離散情報源のシンボル確率の集合は P = \{0.30, 0.20, 0.20, 0.10, 0.10, 0.05, 0.05\} です（合計は 1.00）。
ハフマン符号は、確率の小さいシンボルから順に結合していくという貪欲法（Greedy Algorithm）を用いて構成されます。
ステップ 1: 確率を降順に並べる
まず、シンボルとその確率を降順に並べます。
| シンボル | 確率 |
|---|---|
| S_1 | 0.30 |
| S_2 | 0.20 |
| S_3 | 0.20 |
| S_4 | 0.10 |
| S_5 | 0.10 |
| S_6 | 0.05 |
| S_7 | 0.05 |
ステップ 2: 確率の小さいものから結合
確率の最も小さい2つのシンボル（または中間ノード）を選び、それらを結合して新しいノードを作ります。このプロセスを、最終的に確率が 1.0 の根（ルート）ノードに達するまで繰り返します。
| No. | 結合するノード (確率) | 新しいノードの確率 | 結合後の確率集合 |
|---|---|---|---|
| 1 | (0.05, 0.05) (S_6, S_7) | 0.10 | {0.30, 0.20, 0.20, 0.10, 0.10, 0.10} |
| 2 | (0.10, 0.10) (S_4, S_5) | 0.20 | {0.30, 0.20, 0.20, 0.20, 0.10} (ここでは 0.10 は N_1 のこと) |
| 3 | (0.10, 0.20) (N_1, S_4, S_5) | 0.30 | {0.30, 0.20, 0.20, 0.30} |
| 4 | (0.20, 0.20) (S_2, S_3) | 0.40 | {0.30, 0.30, 0.40} |
| 5 | (0.30, 0.30) (S_1, N_3) | 0.60 | {0.40, 0.60} |
| 6 | (0.40, 0.60) (N_4, N_5) | 1.00 | {1.00} |
ステップ 3: 符号を割り当てる
結合の過程で作られた木（ツリー）の根（確率 1.0）から葉（シンボル）に向かって、左側の枝に \mathbf{0}、右側の枝に \mathbf{1} を割り当てます（割り当て方は逆でも可ですが、一貫性が必要です）。
この結果、各シンボルに対応するハフマン符号と符号長 L_i は以下のようになります。
| シンボル | 確率 P_i | 結合ノード | ハフマン符号 | 符号長 L_i |
|---|---|---|---|---|
| S_1 | 0.30 | N_5 の枝 | 10 | 2 |
| S_2 | 0.20 | N_4 の枝 | 00 | 2 |
| S_3 | 0.20 | N_4 の枝 | 01 | 2 |
| S_4 | 0.10 | N_3 の枝 | 110 | 3 |
| S_5 | 0.10 | N_3 の枝 | 1110 | 4 |
| S_6 | 0.05 | N_1 の枝 | 11110 | 5 |
| S_7 | 0.05 | N_1 の枝 | 11111 | 5 |
> ポイント: 確率が大きいシンボルほど符号長が短くなり、確率が小さいシンボルほど符号長が長くなっていることが分かります。
> 
🧮 平均符号長 L の計算
平均符号長 L は、各シンボルの確率 P_i とその符号長 L_i の積の合計として計算されます。

L = \sum_{i} P_i L_i
L = (0.30 \times 2) + (0.20 \times 2) + (0.20 \times 2) + (0.10 \times 3) + (0.10 \times 4) + (0.05 \times 5) + (0.05 \times 5)
L = 0.60 + 0.40 + 0.40 + 0.30 + 0.40 + 0.25 + 0.25
L = 2.60
✅ 答え
 * ハフマン符号: 上記の表を参照。
 * 平均符号長: 2.60 [ビット/シンボル]
📝 補足：情報源のエントロピー
情報源の平均符号長が達成可能な最小値に近いかどうかを確認するために、情報源のエントロピー H を計算できます。ハフマン符号は、エントロピーに非常に近い平均符号長を与えます。
H = -\sum_{i} P_i \log_2 P_i


H \approx 2.58 \text{ [ビット/シンボル]}

平均符号長 L=2.60 は、エントロピー H \approx 2.58 に非常に近いです。


パリティ検査行列
符号語の長さ（n）
符号語を構成する全ビット数（情報ビット + パリティ検査ビット）は、パリティ検査行列 H の列数 n に等しくなります。
パリティ検査ビットの数（m）
 パリティ検査ビットの数 m は、パリティ検査行列 H の行数に等しくなります。
 情報ビットの数（k）
 情報ビットの数 k は、符号語の長さ n から パリティ検査ビットの数 m を引くことで求められます。
    したがって、符号は**(n, k) 符号**となります。

符号が単一誤り訂正可能であるか否かは、パリティ検査行列 H の列に注目することで判定できます。
判定条件
2元線形符号が単一誤り訂正可能であるための必要十分条件は、パリティ検査行列 H の全ての列が以下の2つの条件を満たすことです。
 * 条件 1: 非ゼロであること
   * H のどの列ベクトルも、すべてゼロのベクトル（ゼロベクトル）であってはならない。
     * 理由：列ベクトルがゼロベクトルである場合、その列に対応する符号語のビットに誤りが発生してもシンドローム s = He^T はゼロのままとなり、誤りが検出できません。
 * 条件 2: 互いに線形独立であること (異なること)
   * H の任意の異なる2つの列ベクトルは、互いに異なるベクトルでなければならない。
     * 理由：もし2つの異なる列 j と l が同じベクトルであった場合、ビット j に発生した単一誤りに対するシンドロームと、ビット l に発生した単一誤りに対するシンドロームが区別できなくなり、どのビットが誤っているかを特定できません（誤り位置が一意に定まらない）。
ハミング符号との関係
単一誤り訂正符号の最もよく知られた例はハミング符号です。符号が単一誤り訂正可能であれば、それは最小ハミング距離が d_{\min} \geq 3 であることを意味します。
まとめ
単一誤り訂正可能であるためには：
> パリティ検査行列 H の列が、
>  * すべて非ゼロであり、かつ
>  * すべて互いに異なる
>    必要があります。

