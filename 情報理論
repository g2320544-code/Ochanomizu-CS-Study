ハフマン符号の構成と平均符号長　　全体なぜなぜそうなるか何に使うか何に使われるから出されているか
ある文字列 (情報) をハフマン符号化する場合、次の1-3を順にすればOK。
各文字(情報)を出現確率（出現頻度）の高い順に並べ、それぞれを独立したグループと考える
各グループの中で、出現確率が低い2つのグループを1つにしていきながら、グループが1つになるまで二分木を作っていく。
作成した二分木から、各文字ごとの符号を求める
各文字ごとに「符号長（符号の文字数） × 出現確率」を求め、それらを足すことで求めることができます
二分木の各節(ノード)の左側を0、右側を1とする
各文字（A～F）ごとに、以下の操作を実施
木構造の一番上の部分から対応するノードまでたどっていく
たどった際に通った0, 1を左から順番に並べたものを符号にする

情報源　エントロピー

エントロピー
ハフマン符号の構成と平均符号長を求める手順を解説します。
💡 ハフマン符号の構成手順
与えられた離散情報源のシンボル確率の集合は P = \{0.30, 0.20, 0.20, 0.10, 0.10, 0.05, 0.05\} です（合計は 1.00）。
ハフマン符号は、確率の小さいシンボルから順に結合していくという貪欲法（Greedy Algorithm）を用いて構成されます。
ステップ 1: 確率を降順に並べる
まず、シンボルとその確率を降順に並べます。
| シンボル | 確率 |
|---|---|
| S_1 | 0.30 |
| S_2 | 0.20 |
| S_3 | 0.20 |
| S_4 | 0.10 |
| S_5 | 0.10 |
| S_6 | 0.05 |
| S_7 | 0.05 |
ステップ 2: 確率の小さいものから結合
確率の最も小さい2つのシンボル（または中間ノード）を選び、それらを結合して新しいノードを作ります。このプロセスを、最終的に確率が 1.0 の根（ルート）ノードに達するまで繰り返します。
| No. | 結合するノード (確率) | 新しいノードの確率 | 結合後の確率集合 |
|---|---|---|---|
| 1 | (0.05, 0.05) (S_6, S_7) | 0.10 | {0.30, 0.20, 0.20, 0.10, 0.10, 0.10} |
| 2 | (0.10, 0.10) (S_4, S_5) | 0.20 | {0.30, 0.20, 0.20, 0.20, 0.10} (ここでは 0.10 は N_1 のこと) |
| 3 | (0.10, 0.20) (N_1, S_4, S_5) | 0.30 | {0.30, 0.20, 0.20, 0.30} |
| 4 | (0.20, 0.20) (S_2, S_3) | 0.40 | {0.30, 0.30, 0.40} |
| 5 | (0.30, 0.30) (S_1, N_3) | 0.60 | {0.40, 0.60} |
| 6 | (0.40, 0.60) (N_4, N_5) | 1.00 | {1.00} |
ステップ 3: 符号を割り当てる
結合の過程で作られた木（ツリー）の根（確率 1.0）から葉（シンボル）に向かって、左側の枝に \mathbf{0}、右側の枝に \mathbf{1} を割り当てます（割り当て方は逆でも可ですが、一貫性が必要です）。
この結果、各シンボルに対応するハフマン符号と符号長 L_i は以下のようになります。
| シンボル | 確率 P_i | 結合ノード | ハフマン符号 | 符号長 L_i |
|---|---|---|---|---|
| S_1 | 0.30 | N_5 の枝 | 10 | 2 |
| S_2 | 0.20 | N_4 の枝 | 00 | 2 |
| S_3 | 0.20 | N_4 の枝 | 01 | 2 |
| S_4 | 0.10 | N_3 の枝 | 110 | 3 |
| S_5 | 0.10 | N_3 の枝 | 1110 | 4 |
| S_6 | 0.05 | N_1 の枝 | 11110 | 5 |
| S_7 | 0.05 | N_1 の枝 | 11111 | 5 |
> ポイント: 確率が大きいシンボルほど符号長が短くなり、確率が小さいシンボルほど符号長が長くなっていることが分かります。
> 
🧮 平均符号長 L の計算
平均符号長 L は、各シンボルの確率 P_i とその符号長 L_i の積の合計として計算されます。

L = \sum_{i} P_i L_i
L = (0.30 \times 2) + (0.20 \times 2) + (0.20 \times 2) + (0.10 \times 3) + (0.10 \times 4) + (0.05 \times 5) + (0.05 \times 5)
L = 0.60 + 0.40 + 0.40 + 0.30 + 0.40 + 0.25 + 0.25
L = 2.60
✅ 答え
 * ハフマン符号: 上記の表を参照。
 * 平均符号長: 2.60 [ビット/シンボル]
📝 補足：情報源のエントロピー
情報源の平均符号長が達成可能な最小値に近いかどうかを確認するために、情報源のエントロピー H を計算できます。ハフマン符号は、エントロピーに非常に近い平均符号長を与えます。
H = -\sum_{i} P_i \log_2 P_i


H \approx 2.58 \text{ [ビット/シンボル]}

平均符号長 L=2.60 は、エントロピー H \approx 2.58 に非常に近いです。


パリティ検査行列
符号語の長さ（n）
符号語を構成する全ビット数（情報ビット + パリティ検査ビット）は、パリティ検査行列 H の列数 n に等しくなります。
パリティ検査ビットの数（m）
 パリティ検査ビットの数 m は、パリティ検査行列 H の行数に等しくなります。
 情報ビットの数（k）
 情報ビットの数 k は、符号語の長さ n から パリティ検査ビットの数 m を引くことで求められます。
    したがって、符号は**(n, k) 符号**となります。

符号が単一誤り訂正可能であるか否かは、パリティ検査行列 H の列に注目することで判定できます。
判定条件
2元線形符号が単一誤り訂正可能であるための必要十分条件は、パリティ検査行列 H の全ての列が以下の2つの条件を満たすことです。
 * 条件 1: 非ゼロであること
   * H のどの列ベクトルも、すべてゼロのベクトル（ゼロベクトル）であってはならない。
     * 理由：列ベクトルがゼロベクトルである場合、その列に対応する符号語のビットに誤りが発生してもシンドローム s = He^T はゼロのままとなり、誤りが検出できません。
 * 条件 2: 互いに線形独立であること (異なること)
   * H の任意の異なる2つの列ベクトルは、互いに異なるベクトルでなければならない。
     * 理由：もし2つの異なる列 j と l が同じベクトルであった場合、ビット j に発生した単一誤りに対するシンドロームと、ビット l に発生した単一誤りに対するシンドロームが区別できなくなり、どのビットが誤っているかを特定できません（誤り位置が一意に定まらない）。
ハミング符号との関係
単一誤り訂正符号の最もよく知られた例はハミング符号です。符号が単一誤り訂正可能であれば、それは最小ハミング距離が d_{\min} \geq 3 であることを意味します。
まとめ
単一誤り訂正可能であるためには：
> パリティ検査行列 H の列が、
>  * すべて非ゼロであり、かつ
>  * すべて互いに異なる
>    必要があります。

与えられたパリティ検査行列 H から、その符号の符号語すべてを書き上げるには、まずその符号の生成行列 G を求めるのが最も一般的な手順です。
🔑 ステップ 1: パリティ検査行列 H から生成行列 G を求める
与えられた線形符号の符号語 \mathbf{c} は、パリティ検査行列 H を用いて次のように定義されます。
\mathbf{c} H^T = \mathbf{0}
符号が組織符号（Systematic Code）として表される場合、パリティ検査行列 H は通常、以下の形に変形できます。
H = [\mathbf{P}^T \mid I_{m}]
ここで、
 * I_m は m \times m の単位行列（m はパリティ検査ビットの数）
 * \mathbf{P}^T は m \times k の行列（k は情報ビットの数）
この形式のとき、符号の生成行列 G は、以下の形になります。
G = [I_{k} \mid \mathbf{P}]
ここで、I_k は k \times k の単位行列です。
具体的な手順
 * 与えられたパリティ検査行列 H に対して、行基本変形（ガウスの消去法）を適用し、H の右側（または左側）に単位行列 I_m が現れるように標準形 [ \mathbf{P}^T \mid I_m ] に変形します。
 * 標準形に変形できたら、その H の左側の行列が \mathbf{P}^T の転置（\mathbf{P}^T）なので、その転置 \mathbf{P} を求めます。
 * G = [I_{k} \mid \mathbf{P}] を構成します。
📝 ステップ 2: すべての符号語を生成する
符号が (n, k) 線形符号である場合、情報ビットの数 k に対して、符号語の総数は 2^k 個になります。
生成行列 G が求められたら、符号語 \mathbf{c} は、すべての可能な情報ベクトル \mathbf{u}（長さ k の 2^k 通りの 0 と 1 の組み合わせ）を用いて計算されます。
\mathbf{c} = \mathbf{u} G
ここで、
 * \mathbf{u} は長さ k の情報ベクトル（例: k=3 なら \mathbf{u} = [000], [001], \dots, [111] の計 2^3=8 通り）
 * G は k \times n の生成行列
 * 計算はすべて \text{GF}(2) 上（つまり、2を法とする加算、排他的論理和 \oplus）で行います。
具体的な手順
 * k を求め、情報ベクトル \mathbf{u} のすべての組み合わせ（2^k 通り）を書き出します。
 * それぞれの \mathbf{u} に対して、\mathbf{c} = \mathbf{u} G の計算を実行します。
 * 計算結果として得られた 2^k 個のベクトル \mathbf{c} が、その符号のすべての符号語です。
💡 例：(5, 3) 符号の場合
情報ビットの数 k=3、符号語の長さ n=5 の符号を考えます。
 * 符号語の数は 2^3 = 8 個。
 * 生成行列 G が例えば次のように求まったとします。
   
   G = \begin{pmatrix} 1 & 0 & 0 & 1 & 1 \\ 0 & 1 & 0 & 1 & 0 \\ 0 & 0 & 1 & 0 & 1 \end{pmatrix}
| 情報ベクトル \mathbf{u} | 計算 \mathbf{c} = \mathbf{u} G | 符号語 \mathbf{c} |
|---|---|---|
| [0 0 0] | [000] G | [0 0 0 0 0] |
| [1 0 0] | [100] G | [1 0 0 1 1] (Gの1行目) |
| [0 1 0] | [010] G | [0 1 0 1 0] (Gの2行目) |
| [0 0 1] | [001] G | [0 0 1 0 1] (Gの3行目) |
| [1 1 0] | [100] G \oplus [010] G | [1 1 0 0 1] ([10011] \oplus [01010]) |
| [1 0 1] | [100] G \oplus [001] G | [1 0 1 1 0] ([10011] \oplus [00101]) |
| [0 1 1] | [010] G \oplus [001] G | [0 1 1 1 1] ([01010] \oplus [00101]) |
| [1 1 1] | [110] G \oplus [001] G | [1 1 1 0 0] ([11001] \oplus [00101]) |
このように、情報ベクトルの全パターンを生成行列 G にかけることで、すべての符号語を書き出すことができます。


